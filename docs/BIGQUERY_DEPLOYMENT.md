# BigQuery Deployment Guide - Option A (Single Dataset)

Bu rehber, Sentilyze Unified projesi iÃ§in **tek dataset** mimarisinde BigQuery yapÄ±landÄ±rmasÄ±nÄ± aÃ§Ä±klar.

## ğŸ“Š Mimari Ã–zeti

**Dataset:** `sentilyze_dataset`

**Tablolar (7 adet):**

| Tablo | Katman | AmaÃ§ | BÃ¶lÃ¼mleme | KÃ¼meleme |
|-------|--------|------|-----------|----------|
| `raw_data` | Bronze | Ham ingestion verileri | `timestamp` (GÃœN) | `market_type`, `data_source` |
| `sentiment_analysis` | Silver | Ä°ÅŸlenmiÅŸ sentiment verileri | `timestamp` (GÃœN) | `market_type`, `sentiment_label` |
| `market_context` | Silver | Piyasa indikatÃ¶rleri | `timestamp` (GÃœN) | `market_type`, `asset_symbol` |
| `predictions` | Gold | AI/ML tahminleri | `prediction_timestamp` (GÃœN) | `market_type`, `asset_symbol`, `prediction_type` |
| `prediction_accuracy` | Gold | Tahmin doÄŸruluk sonuÃ§larÄ± | `validation_timestamp` (GÃœN) | `market_type`, `asset_symbol` |
| `alerts` | Gold | Alert bildirimleri | `created_at` (GÃœN) | `market_type`, `alert_type`, `severity` |
| `analytics_summary` | Gold | GÃ¼nlÃ¼k Ã¶zet analytics | `date` (GÃœN) | `market_type` |

**View'lar (4 adet):**

| View | AmaÃ§ |
|------|------|
| `daily_sentiment_summary` | GÃ¼nlÃ¼k sentiment toplamlarÄ± |
| `prediction_performance` | Tahmin performans metrikleri |
| `crypto_market_overview` | Kripto piyasa Ã¶zeti |
| `gold_market_overview` | AltÄ±n piyasa Ã¶zeti |

---

## ğŸš€ Deployment SeÃ§enekleri

### SeÃ§enek 1: Terraform ile (Ã–nerilen - Production)

```bash
# 1. Terraform'u baÅŸlat
cd infrastructure/terraform

# 2. GCP kimlik bilgilerini ayarla
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json

# 3. Terraform deÄŸiÅŸkenlerini ayarla
cat > terraform.tfvars <<EOF
project_id = "your-gcp-project-id"
region = "us-central1"
dataset_id = "sentilyze_dataset"
dataset_location = "US"
EOF

# 4. Terraform plan'Ä± gÃ¶zden geÃ§ir
terraform plan

# 5. Deploy et
terraform apply

# 6. View'larÄ± oluÅŸtur (manuel veya terraform output)
terraform output view_creation_commands
```

**Terraform ile oluÅŸturulan kaynaklar:**
- âœ… Dataset: `sentilyze_dataset`
- âœ… 7 tablo (partitioning ve clustering ile)
- âœ… 4 view
- âœ… Gerekli IAM rolleri
- âœ… Data retention politikalarÄ±

---

### SeÃ§enek 2: bq_setup.py Tool ile (Development/Local)

```bash
# 1. Ortam deÄŸiÅŸkenlerini ayarla
export GCP_PROJECT_ID=your-project-id
export BIGQUERY_DATASET=sentilyze_dataset
export BIGQUERY_LOCATION=US

# 2. Python tool'u Ã§alÄ±ÅŸtÄ±r
cd tools
python bq_setup.py \
  --project-id $GCP_PROJECT_ID \
  --dataset $BIGQUERY_DATASET \
  --location $BIGQUERY_LOCATION \
  --create-tables \
  --create-views

# 3. Schema'larÄ± doÄŸrula
python bq_setup.py \
  --project-id $GCP_PROJECT_ID \
  --dataset $BIGQUERY_DATASET \
  --validate-schemas
```

---

### SeÃ§enek 3: Manuel SQL ile (HÄ±zlÄ± Test)

```bash
# BigQuery'e baÄŸlan
bq query --use_legacy_sql=false
```

```sql
-- 1. Dataset oluÅŸtur
CREATE SCHEMA IF NOT EXISTS `your-project-id.sentilyze_dataset`
OPTIONS(
  location="US",
  description="Sentilyze unified dataset for crypto and gold market sentiment analysis",
  labels=[("project", "sentilyze"), ("environment", "production")]
);

-- 2. TablolarÄ± oluÅŸtur (aÅŸaÄŸÄ±daki SQL script'lerini Ã§alÄ±ÅŸtÄ±r)
-- Infrastructure/terraform/schemas/ dizinindeki JSON schema'larÄ± kullan
```

---

## ğŸ“‹ AdÄ±m AdÄ±m Kurulum

### AdÄ±m 1: Ã–nce GCP Projesi HazÄ±rlÄ±ÄŸÄ±

```bash
# GCP projesi seÃ§
export GCP_PROJECT_ID=your-project-id
gcloud config set project $GCP_PROJECT_ID

# Gerekli API'leri etkinleÅŸtir
gcloud services enable bigquery.googleapis.com
gcloud services enable bigquerystorage.googleapis.com

# Service account oluÅŸtur (eÄŸer yoksa)
gcloud iam service-accounts create sentilyze-bq \
  --display-name="Sentilyze BigQuery Service Account"

# Service account'a BigQuery yetkileri ver
gcloud projects add-iam-policy-binding $GCP_PROJECT_ID \
  --member="serviceAccount:sentilyze-bq@$GCP_PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/bigquery.dataEditor"

gcloud projects add-iam-policy-binding $GCP_PROJECT_ID \
  --member="serviceAccount:sentilyze-bq@$GCP_PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/bigquery.jobUser"

# Service account key oluÅŸtur (development iÃ§in - production'da Workload Identity kullanÄ±n)
gcloud iam service-accounts keys create ~/sentilyze-bq-key.json \
  --iam-account=sentilyze-bq@$GCP_PROJECT_ID.iam.gserviceaccount.com

# Key'i ortam deÄŸiÅŸkeni olarak ayarla
export GOOGLE_APPLICATION_CREDENTIALS=~/sentilyze-bq-key.json
```

---

### AdÄ±m 2: Dataset ve TablolarÄ± OluÅŸturma

#### Terraform YÃ¶ntemi (Production iÃ§in Ã¶nerilen):

```bash
cd infrastructure/terraform

# terraform.tfvars dosyasÄ±nÄ± oluÅŸtur
cat > terraform.tfvars <<EOF
project_id = "${GCP_PROJECT_ID}"
region = "us-central1"
zone = "us-central1-a"

dataset_id = "sentilyze_dataset"
dataset_location = "US"
dataset_description = "Sentilyze unified dataset for crypto and gold market sentiment analysis"

# Data retention (gÃ¼n olarak)
raw_data_retention_days = 90
processed_data_retention_days = 365
analytics_retention_days = 0  # 0 = no expiration

# Feature flags
enable_crypto_market = true
enable_gold_market = true
EOF

# Deploy
terraform init
terraform plan
terraform apply -auto-approve
```

#### Python Tool YÃ¶ntemi (GeliÅŸtirme iÃ§in):

```bash
# Gerekli paketleri kur
pip install google-cloud-bigquery

# Tool'u Ã§alÄ±ÅŸtÄ±r
python tools/bq_setup.py \
  --project-id $GCP_PROJECT_ID \
  --dataset sentilyze_dataset \
  --location US \
  --environment prod \
  --create-all
```

---

### AdÄ±m 3: Ortam DeÄŸiÅŸkenlerini Ayarlama

`.env` dosyanÄ±zÄ± ÅŸu ÅŸekilde gÃ¼ncelleyin:

```bash
# ============================================
# BigQuery Configuration (Single Dataset - Option A)
# ============================================
BIGQUERY_DATASET=sentilyze_dataset
BIGQUERY_LOCATION=US
BIGQUERY_EMULATOR_HOST=  # Production'da boÅŸ bÄ±rakÄ±n

# GCP Kimlik Bilgileri (Production'da Secret Manager kullanÄ±n)
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account-key.json
```

---

### AdÄ±m 4: DoÄŸrulama ve Test

```bash
# 1. Dataset'in oluÅŸtuÄŸunu kontrol et
export GCP_PROJECT_ID=your-project-id
bq ls $GCP_PROJECT_ID:sentilyze_dataset

# 2. TablolarÄ± listele
bq ls $GCP_PROJECT_ID:sentilyze_dataset

# 3. Tablo ÅŸemalarÄ±nÄ± kontrol et
bq show $GCP_PROJECT_ID:sentilyze_dataset.raw_data
bq show $GCP_PROJECT_ID:sentilyze_dataset.sentiment_analysis

# 4. Test verisi ekle
cat > test_data.json <<EOF
{"event_id": "test-001", "timestamp": "2026-01-31T12:00:00Z", "market_type": "crypto", "data_source": "test", "content": "Test event", "metadata": "{}"}
EOF

bq load \
  --source_format=NEWLINE_DELIMITED_JSON \
  $GCP_PROJECT_ID:sentilyze_dataset.raw_data \
  test_data.json

# 5. Veriyi sorgula
bq query --use_legacy_sql=false \
  "SELECT * FROM \`$GCP_PROJECT_ID.sentilyze_dataset.raw_data\` LIMIT 10"

# 6. Test verisini temizle
rm test_data.json
bq query --use_legacy_sql=false \
  "DELETE FROM \`$GCP_PROJECT_ID.sentilyze_dataset.raw_data\` WHERE event_id = 'test-001'"
```

---

## ğŸ“Š Data Retention PolitikasÄ±

| Tablo | Retention | AÃ§Ä±klama |
|-------|-----------|----------|
| `raw_data` | 90 gÃ¼n | Ham veriler 90 gÃ¼n sonra otomatik silinir |
| `sentiment_analysis` | 365 gÃ¼n | Ä°ÅŸlenmiÅŸ veriler 1 yÄ±l saklanÄ±r |
| `market_context` | 365 gÃ¼n | Piyasa verileri 1 yÄ±l saklanÄ±r |
| `predictions` | 0 (sonsuz) | Tahminler kalÄ±cÄ± saklanÄ±r |
| `prediction_accuracy` | 0 (sonsuz) | DoÄŸruluk metrikleri kalÄ±cÄ± |
| `alerts` | 180 gÃ¼n | Alert'ler 6 ay saklanÄ±r |
| `analytics_summary` | 0 (sonsuz) | Ã–zet analytics kalÄ±cÄ± |

**Retention ayarÄ±:**
```sql
-- Tablo dÃ¼zeyinde retention ayarÄ± (gÃ¼n olarak)
ALTER TABLE `project.dataset.table`
SET OPTIONS (
  expiration_timestamp = TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 90 DAY)
);
```

---

## ğŸ” GÃ¼venlik ve IAM

### Gerekli Roller

| Rol | Kim | AmaÃ§ |
|-----|-----|------|
| `roles/bigquery.dataEditor` | Uygulama servisleri | Veri okuma/yazma |
| `roles/bigquery.jobUser` | Uygulama servisleri | Query Ã§alÄ±ÅŸtÄ±rma |
| `roles/bigquery.dataViewer` | Analiz kullanÄ±cÄ±larÄ± | Sadece okuma |
| `roles/bigquery.admin` | DevOps/Admin | Tam yÃ¶netim |

### IAM Atama

```bash
# Servis account iÃ§in (Ã¶rnek: sentilyze-bq@sentilyze-v5-clean.iam.gserviceaccount.com)
export SERVICE_ACCOUNT="sentilyze-bq@$GCP_PROJECT_ID.iam.gserviceaccount.com"

# Data Editor (okuma/yazma)
gcloud projects add-iam-policy-binding $GCP_PROJECT_ID \
  --member="serviceAccount:$SERVICE_ACCOUNT" \
  --role="roles/bigquery.dataEditor"

# Job User (query Ã§alÄ±ÅŸtÄ±rma)
gcloud projects add-iam-policy-binding $GCP_PROJECT_ID \
  --member="serviceAccount:$SERVICE_ACCOUNT" \
  --role="roles/bigquery.jobUser"

# Dataset seviyesinde yetki (daha gÃ¼venli)
bq query --use_legacy_sql=false \
  "GRANT SELECT, INSERT, UPDATE, DELETE ON SCHEMA \`$GCP_PROJECT_ID.sentilyze_dataset\` TO 'serviceAccount:$SERVICE_ACCOUNT'"
```

---

## ğŸ’° Maliyet Optimizasyonu

### Partitioning FaydalarÄ±

- **Storage:** Sadece aktif partition'lar iÃ§in Ã¶deme yapÄ±lÄ±r
- **Query:** Sadece ilgili partition'lar taranÄ±r (masraf azalÄ±r)
- **Time-travel:** 7 gÃ¼n Ã¼cretsiz time-travel desteÄŸi

### Maliyet Tahmini (aylÄ±k)

| KullanÄ±m | Storage | Query | Toplam |
|----------|---------|-------|--------|
| 100GB veri | ~$2 | ~$5 | ~$7 |
| 1TB veri | ~$20 | ~$25 | ~$45 |
| 10TB veri | ~$200 | ~$100 | ~$300 |

**Not:** Partitioning ve clustering ile query maliyetleri %50-70 azalabilir.

---

## ğŸ› ï¸ Troubleshooting

### Sorun 1: Dataset zaten var

```bash
# Dataset'i sil ve yeniden oluÅŸtur (DÄ°KKAT: Veri kaybÄ±!)
bq rm -r -f -d $GCP_PROJECT_ID:sentilyze_dataset
terraform apply
```

### Sorun 2: Tablo ÅŸemasÄ± uyuÅŸmazlÄ±ÄŸÄ±

```bash
# Schema doÄŸrulama
python tools/bq_setup.py \
  --project-id $GCP_PROJECT_ID \
  --dataset sentilyze_dataset \
  --validate-schemas

# Tabloyu sil ve yeniden oluÅŸtur
bq rm -f -t $GCP_PROJECT_ID:sentilyze_dataset.raw_data
terraform apply
```

### Sorun 3: Permission denied

```bash
# Service account yetkilerini kontrol et
gcloud projects get-iam-policy $GCP_PROJECT_ID \
  --flatten="bindings[].members" \
  --format="table(bindings.role)" \
  --filter="bindings.members:sentilyze-bq"

# Ã–rnek: sentilyze-v5-clean projesi iÃ§in kontrol
gcloud projects get-iam-policy sentilyze-v5-clean \
  --flatten="bindings[].members" \
  --format="table(bindings.role,bindings.members)" \
  --filter="bindings.members:sentilyze-bq"

# Yetkileri yenile
gcloud auth application-default login
```

---

## ğŸ“š Ã–nemli Notlar

1. **Emulator ile Development:**
   ```bash
   # Local development iÃ§in BigQuery emulator kullan
   docker-compose up bigquery-emulator
   # Emulator'da partitioning ve clustering desteÄŸi sÄ±nÄ±rlÄ± olabilir
   ```

2. **Production Deployment:**
   - Asla `GOOGLE_APPLICATION_CREDENTIALS` ile key dosyasÄ± kullanmayÄ±n
   - Workload Identity veya Secret Manager kullanÄ±n
   - Terraform state'ini remote backend'de (GCS) saklayÄ±n

3. **Monitoring:**
   ```bash
   # BigQuery slot kullanÄ±mÄ±nÄ± izle
   gcloud monitoring metrics list --filter="bigquery"
   ```

4. **Backup:**
   ```bash
   # Dataset'i baÅŸka bÃ¶lgeye kopyala (yedekleme)
   bq cp -a $GCP_PROJECT_ID:sentilyze_dataset $GCP_PROJECT_ID:sentilyze_dataset_backup
   ```

---

## âœ… Deployment Checklist

- [ ] GCP projesi oluÅŸturuldu
- [ ] Gerekli API'ler etkinleÅŸtirildi
- [ ] Service account oluÅŸturuldu
- [ ] IAM rolleri atandÄ±
- [ ] Dataset oluÅŸturuldu (`sentilyze_dataset`)
- [ ] 7 tablo oluÅŸturuldu (partitioning + clustering)
- [ ] 4 view oluÅŸturuldu
- [ ] `.env` dosyasÄ± gÃ¼ncellendi
- [ ] Test verisi eklendi ve sorgulandÄ±
- [ ] Data retention politikalarÄ± doÄŸrulandÄ±
- [ ] Maliyet limitleri ayarlandÄ± (`BIGQUERY_MAX_BYTES_BILLED`)

---

## ğŸš€ Sonraki AdÄ±mlar

BigQuery deployment tamamlandÄ±ktan sonra:

1. **Pub/Sub topics ve subscriptions** oluÅŸtur
2. **Redis/Firestore** cache'i yapÄ±landÄ±r
3. **Servisleri deploy et:** `docker-compose up` veya Cloud Run
4. **Health check endpoint'lerini** test et: `curl http://localhost:8080/health`
5. **End-to-end test** yap: Veri ingestion â†’ Sentiment analysis â†’ BigQuery storage

---

**Son GÃ¼ncelleme:** 31 Ocak 2026  
**Versiyon:** 4.0.0  
**Mimari:** Single Dataset (Option A)
